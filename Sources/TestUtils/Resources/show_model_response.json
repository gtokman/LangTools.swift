{
  "modelfile": "# Modelfile generated by \"ollama show\"\nFROM /models/blobs/sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711ab\nTEMPLATE \"\"\"\nUSER: {{ .Prompt }}\nASSISTANT: \"\"\"\nPARAMETER stop \"<s>\"",
  "parameters": "num_ctx 4096",
  "template": "{{ if .System }}{{ .System }}{{ end }}{{ if .Prompt }}USER: {{ .Prompt }}{{ end }}ASSISTANT: {{ .Response }}",
  "details": {
    "format": "gguf",
    "family": "llama",
    "families": ["llama"],
    "parameter_size": "7B",
    "quantization_level": "Q4_0"
  },
  "model_info": {
    "format": "gguf",
    "architecture": "llama",
    "vocab_size": 32000,
    "num_attention_heads": 32,
    "num_hidden_layers": 32,
    "hidden_size": 4096
  }
}
